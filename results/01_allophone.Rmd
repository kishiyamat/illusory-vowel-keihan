---
title: "Allophone"
output: github_document
---

todo

1. 被験者ごとのデータをまとめる
  * 産出課題: 無声化率(環境毎)
  * 近畿の居住年数
1. 被験者ごとのデータをまとめる
  * 無声化
    * AXB
    * 判定課題
  * トーンの復元
  
タスクの確認

item_id がないのは練習問題

* production
* axb
  * item_id でタスクが分かれる
* cat
  * item_id でタスクが分かれる
* rate(音としてどれくらい良いか)
  * item_id でタスクが分かれる
  
無声化
https://docs.google.com/document/d/1OKkkZ4sELLtTBjiBWUG_P37EsWdFsidrGv0eOqiwIic/edit?usp=sharing

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(tidyr)
source("script/subject_info.R")
source("script/results_pitch.R") # load mutated data
```

```{r}
item_list <- read_csv("../src/list/axb_list.csv") %>%
  select(c(item_id, type, condition, correct, item_a, item_x, item_b, c1, c2))
subject_info_sone <- read_csv("csv/illusory-vowel-keihan.csv") %>%
  extract_columns(data_src = "sone")
subject_info_cw <- read_csv("csv/illusory-vowel-keihan-cw.csv") %>%
  extract_columns(data_src = "cw")
subject_info <- rbind(subject_info_sone, subject_info_cw)

results <- rbind(
  read_csv("csv/illusory-vowel-keihan.csv") %>% mutate(data_src = "sone"),
  read_csv("csv/illusory-vowel-keihan-cw.csv") %>% mutate(data_src = "cw")
) %>%
  filter(task == "axb") %>%
  left_join(subject_info, by = c("run_id", "data_src")) %>%
  select(c(run_id, item_id, is_correct, rt, span_kinki, span_tokyo, span_unknown, age, data_src, correct)) %>%
  mutate(item_id = as.numeric(item_id)) %>%
  mutate(rt = as.numeric(rt)) %>%
  mutate(item_id = as.numeric(item_id)) %>%
  mutate(is_correct = is_correct == "true") %>%
  # boolにしている
  drop_na() %>%
  mutate(
    span_tokyo_span_kinki = span_tokyo - span_kinki,
    tokyo_kinki_ratio = (span_tokyo - span_kinki) / age
  ) %>%
  filter(age > 18) %>%
  merge(item_list, on = "item_id") %>%
  filter(type == "target") %>%
  group_by(c1, c2, run_id, data_src) %>%
  mutate(
    is_correct_mean = mean(is_correct),
    phoneme_envs = paste0(c1, "-", c2),
    subject_id = paste0(data_src, "-", run_id)
  ) %>%
  mutate(
    pair = case_when(
      phoneme_envs %in% c("s-p", "z-b") ~ "s-p",
      phoneme_envs %in% c("p-s", "b-z") ~ "p-s",
      phoneme_envs %in% c("k-t", "g-d") ~ "k-t",
      phoneme_envs %in% c("ts-k", "dz-g") ~ "ts-k"
    ),
  )
```

アイテムリストのマージ

```{r}
head(results, 100)
results$phoneme_envs %>% unique()
```

```{r}
results %>%
  ggplot() +
  facet_grid(pair ~ condition) +
  geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 5),
    y = is_correct_mean,
    color = phoneme_envs,
    fill = phoneme_envs,
  ))
```

全体的に有声音の環境ではアイテムの作成の難しさから弁別が用意になっているかもしれない。

- まぁ普通に近畿で錯覚が増えていることにはならない
- bzの方がps より錯覚が起きやすい

```{r}
library(lmerTest)
model <- lmer(
  is_correct_mean ~
  condition * pair + tokyo_kinki_ratio + (1 | subject_id),
  data = results
)

# 居住歴の効果はない(トーンの錯覚とは対照的)
summary(model)
```

- voiced になると下がる(ベースライン)
  - p-s, s-p では voiced になると上がる(先行研究と同じ)
  - ts-k は下がる, k-t も下がる（おそらくベースライン）
- p-s や p-s、ts-k は下がる
  - 摩擦や破裂、といった要素でモデリングしたほうが良さそう

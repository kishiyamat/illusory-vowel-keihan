---
title: "Allophone"
output: github_document
---

01でallophoneの効果を見るが、そもそも受け入れられるかは
03のcatで見ており、これは「音声としての自然さ」として解釈できる。
<!--
論文としてのまとめ方はkilpatrickを参考に進める。
https://drive.google.com/drive/folders/1-Dfuzcas58w9ERrDzoPggfp9vIAjPo7_
-->

被験者ごとに voiced-voiceless を求めるか。

- 独立変数
  - 被験者要因(居住歴|無声化率)
- 従属変数
1. 被験者ごとのデータをまとめる
  * 産出課題: 無声化率(環境毎)
  * *居住歴* (tokyo_kinki_ratio)
  - ランダム効果  
1. 被験者ごとのデータをまとめる
  * 無声化
    * AXB
    * 判定課題
  * トーンの復元
  
https://docs.google.com/document/d/1OKkkZ4sELLtTBjiBWUG_P37EsWdFsidrGv0eOqiwIic/edit?usp=sharing

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(tidyr)
library(lmerTest)
source("script/subject_info.R")
source("script/results_pitch.R") # load mutated data

knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
# install.packages("remotes")
# remotes::install_github("easystats/easystats")
library(rstanarm)
library("bayestestR")
```

```{r}
item_list <- read_csv("../src/list/axb_list.csv") %>%
  select(c(item_id, type, condition, correct, item_a, item_x, item_b, c1, c2))
subject_info_sone <- read_csv("csv/illusory-vowel-keihan.csv") %>%
  extract_columns(data_src = "sone")
subject_info_cw <- read_csv("csv/illusory-vowel-keihan-cw.csv") %>%
  extract_columns(data_src = "cw")
subject_info <- rbind(subject_info_sone, subject_info_cw)

results <- rbind(
  read_csv("csv/illusory-vowel-keihan.csv") %>% mutate(data_src = "sone"),
  read_csv("csv/illusory-vowel-keihan-cw.csv") %>% mutate(data_src = "cw")
) %>%
  filter(task == "axb") %>%
  left_join(subject_info, by = c("run_id", "data_src")) %>%
  select(c(run_id, item_id, is_correct, rt, span_kinki, span_tokyo, span_unknown, age, data_src, correct)) %>%
  mutate(
    item_id = as.numeric(item_id),
    rt = as.numeric(rt),
    item_id = as.numeric(item_id),
    is_correct = is_correct == "true"
  ) %>%
  drop_na() %>%
  mutate(
    tokyo_kinki_ratio = (span_tokyo - span_kinki) / age
  ) %>%
  filter(age > 18) %>%
  merge(item_list, on = "item_id") %>%
  filter(type == "target") %>%
  mutate(
    phoneme_envs = paste0(c1, "-", c2),
    subject_id = paste0(data_src, "-", run_id),
    pair = case_when(
      phoneme_envs %in% c("s-p", "z-b") ~ "s-p",
      phoneme_envs %in% c("p-s", "b-z") ~ "p-s",
      phoneme_envs %in% c("k-t", "g-d") ~ "k-t",
      phoneme_envs %in% c("ts-k", "dz-g") ~ "ts-k"
    )
  )
nrow(results)
```

```{r}
# 右裾の確認, 10s 以上は外れ値とする
results %>%
  select(rt) %>%
  unlist() %>%
  hist(breaks = 100)
# 左裾はそこまで以上な値はなさそう.
results %>%
  filter(rt < 400) %>%
  select(rt) %>%
  unlist() %>%
  hist(breaks = 100)
# 対数を取って反応の正規分布を確認, 2sd以上の反応は除外
results_filtered <- results %>% filter(between(rt, 0, 15000))
# FIXME: ここらへんのデータ処理はあとできれいにかく（丸めも必要）
# hist(log(results_filtered$rt))
# sd_log_rt = 2*sd(log(results_filtered$rt))
# mean_log_rt = mean(log(results_filtered$rt))
# floor_log_rt = mean_log_rt-sd_log_rt
# ceil_log_rt = mean_log_rt+sd_log_rt
# print(floor_log_rt)
# print(ceil_log_rt)
# results_filtered = results_filtered %>%
#   mutate(log_rt = log(rt)) %>% filter(between(log_rt,floor_log_rt,ceil_log_rt))
results_filtered$rt %>%
  summary() %>%
  print()
print(nrow(results_filtered))
```


```{r}
results_mean <- results_filtered %>%
  group_by(subject_id, tokyo_kinki_ratio, pair, condition, phoneme_envs) %>%
  # item_idがあるとebzo ebuzo ebuzoとebuzo ebuzo ebzoで分かれて平均できない
  mutate(
    # ここ、NAがあるならどうなる？
    is_correct_mean = mean(is_correct, na.rm = T),
    rt_mean = mean(rt, na.rm = T),
  ) %>%
  select(c(
    subject_id, tokyo_kinki_ratio, span_tokyo, span_kinki,
    pair, condition, phoneme_envs,
    is_correct_mean, rt_mean
  )) %>%
  droplevels() %>%
  distinct()
```

## 可視化

```{r}
# rt
results_mean %>%
  ggplot() +
  facet_grid(pair ~ condition) +
  geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 7),
    y = log(rt_mean),
    color = phoneme_envs,
    fill = phoneme_envs,
  ))

results_mean %>%
  ggplot() +
  facet_grid(pair ~ condition) +
  geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 7),
    y = is_correct_mean,
    color = phoneme_envs,
    fill = phoneme_envs,
  ))
```

## 分析

### 交互作用(正答率)

LME

- voicedだと正答率が下がる

```{r}
# ペアなし交互作用
model <- lmer(
  is_correct_mean ~
    condition * tokyo_kinki_ratio + (1 | subject_id),
  data = results_mean
)
summary(model)
```

ベイズファクター

```{r}
# https://easystats.github.io/bayestestR/articles/bayes_factors.html
model <- stan_lmer(
  formula = is_correct_mean ~ condition * tokyo_kinki_ratio+ (1 | subject_id),
  data = results_mean,
  # 平均は0でバラツキも0.5としよう
  # 効果は0を中心として、せいぜい+-0.5くらい。
  prior = normal(0, 0.5, autoscale = FALSE),
  chains = 10, iter = 5000, warmup = 1000
)
```

```{r}
print(model, digits = 3)
# LME
#                                     Estimate Std. Error         df t value Pr(>|t|)    
# (Intercept)                         0.593200   0.012650 182.828889  46.894   <2e-16 ***
# conditionvoiced                    -0.004368   0.016091 494.999999  -0.271    0.786    
# tokyo_kinki_ratio                   0.014103   0.016073 182.828889   0.877    0.381    
# conditionvoiced:tokyo_kinki_ratio  -0.004327   0.020445 494.999999  -0.212    0.832    
```

正答率を1.4%上げるが、SDも1.6%ある。

```{r}
# 正答率を割合を5%上げる・下げないならそれは無意味
My_first_BF <- bayesfactor_parameters(model, null = c(-0.01, 0.01))
My_first_BF
```

```{r}
library(see)
plot(My_first_BF)
```

### 交互作用(正答率)

有意傾向

```{r}
# ペアなし交互作用
model <- lmer(
  rt_mean ~
    condition * tokyo_kinki_ratio + (1 | subject_id),
  data = results_mean
)
summary(model)
```

### アイテムごと

```{r}
# ペアあり交互作用(補足の分析)
model <- lmer(
  is_correct_mean ~
    condition * pair * tokyo_kinki_ratio + (1 | subject_id),
  data = results_mean
)
summary(model)
```

## Appendix

### バイナリーなのでモデル変更

データをそのまま使うこともできる。

```{r}
model <- lmer(
  rt ~
    # condition * tokyo_kinki_ratio + (1 | subject_id) + (1|pair),
    # condition * pair * tokyo_kinki_ratio + (1 | subject_id),
    condition * pair * tokyo_kinki_ratio + (1 | subject_id),
  # data = results_filtered
  data = (results_filtered %>% filter(pair != "p-s")),
)
summary(model)
```

```{r}
results_filtered %>% filter(pair %in% c("p-s", "s-p"))
model <- glmer(
  is_correct ~
    # condition * tokyo_kinki_ratio + (1 | subject_id) + (1|pair),
    # condition * pair * tokyo_kinki_ratio + (1 | subject_id),
    condition * pair * tokyo_kinki_ratio + (1 | subject_id),
  # data = results_filtered,
  data = (results_filtered %>% filter(pair %in% c("p-s", "s-p"))),
  family = binomial
)
print(nrow(results_filtered))
# 居住歴の効果はない(トーンの錯覚とは対照的)
summary(model)
```

- voiced になると下がる(ベースライン)
  - p-s, s-p では voiced になると上がる(先行研究と同じ)
  - ts-k は下がる, k-t も下がる（おそらくベースライン）
- p-s や p-s、ts-k は下がる
  - 摩擦や破裂、といった要素でモデリングしたほうが良さそう

効果はなかった。個別の差を分析する感じがよいか。

## デルタ(対応付け)

```{r}
results_mean_delta <- results_mean %>%
  pivot_wider(
    id_cols = c(subject_id, tokyo_kinki_ratio, pair),
    names_from = "condition", values_from = is_correct_mean
  ) %>%
  mutate(delta = voiced - devoiced)
results_mean_delta %>%
  ggplot() +
  facet_grid(pair ~ .) +
  geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 4),
    y = delta,
    # y = is_correct_mean,
    color = pair,
    fill = pair,
  ))
```
```{r}

model <- lmer(
  delta ~
    tokyo_kinki_ratio + (1 | subject_id),
  data = results_mean_delta
  # data = (results_filtered %>% filter(pair!="p-s")),
)
summary(model)
```

```{r}
print("EOF")
```

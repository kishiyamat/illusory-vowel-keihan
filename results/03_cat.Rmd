---
title: "Categorize and Rate"
output: github_document
---

- 概要: https://docs.google.com/document/d/1rk5MHMvD5-6SWT7H2nkc-r7v3KvH-dzt_OdftNrDe-I/edit?usp=sharing
- 作業説明: https://docs.google.com/document/d/1U3FCDh8NETS-9mWDLfTU_0mZx9jJpFgkisukI58nV64/edit?usp=sharing

行う分析

- 東京方言話者と近畿方言話者で無声化した音声に対する許容度は異なるのか
  - 音声の尤度自体は低いはず。P(音声|音素)
    - P(音素|音声) も低くなってほしい。
  - なにかおもしろいことが言えないか

> 音がどの表記（ひらがな）に当てはまり(8候補)、
> choices: ['えすぽ', 'えずぼ', 'えくと', 'えぐど', 'えぷそ', 'えぶぞ', 'えつこ', 'えづご'],
> どの程度一致しているかを1--7段階で評価
> questions: [{ prompt: "聞いた音声は選んだ表記として適切ですか？<br>1: 全く適切でない<br>7: 極めて適切", labels: scale }],

- カテゴライズとしての良し悪し

```{r}
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(tidyr)
source("script/subject_info.R")
source("script/results_pitch.R") # load mutated data
```

1. catのタスクを見る
  1. 想定されたものを選んでもらえたか
  1. 想定されたものとしての評価は低すぎないか
  1. sp とかがナチュラルかも気になる（近畿ではないので）

```{r}
# epuso-1.wavなどのaudio列を.で分割し、最初の要素を stim, spkr とする
item_list <- read_csv("../src/list/cat_list.csv") %>%
  rowwise() %>%
  mutate(
    wav_base = str_split(audio, "\\.")[[1]][1],
    stim = str_split(wav_base, "-")[[1]][1],
    spkr = str_split(wav_base, "-")[[1]][2]
  ) %>%
  select(-c(task, audio, wav_base))

# 被験者情報
subject_info_sone <- read_csv("csv/illusory-vowel-keihan.csv") %>%
  extract_columns(data_src = "sone")
subject_info_cw <- read_csv("csv/illusory-vowel-keihan-cw.csv") %>%
  extract_columns(data_src = "cw")
subject_info <- rbind(subject_info_sone, subject_info_cw) %>%
  mutate(tokyo_kinki_ratio = (span_tokyo - span_kinki) / age)

# cwデータと曽根さんデータのマージ
results_bound <- rbind(
  read_csv("csv/illusory-vowel-keihan.csv") %>% mutate(data_src = "sone"),
  read_csv("csv/illusory-vowel-keihan-cw.csv") %>% mutate(data_src = "cw")
)
```

1. catでの選択を特定
1. rateの抜き出し
1. catのDFの横につける
1. 必要な列を作成
  1. `stim_devoiced`: 刺激はdevoicedされたか
  1. `dev_env`: 無声化環境か
  1. `pair`: どのペアなのか（調音点）
  1. `supposed_answer`: espoもesupoも'えすぽ(esupo)'と回答(choice)してほしい

```{r}
# catでの選択を特定する(indexは1始まりなので+1する)
results_cat <- results_bound %>% filter(task == "cat")
selected_idx <- results_cat %>%
  select(response) %>%
  unlist() %>%
  as.integer()
# choices = c('えすぽ', 'えずぼ', 'えくと', 'えぐど', 'えぷそ', 'えぶぞ', 'えつこ', 'えづご')
choices <- c("esupo", "ezubo", "ekuto", "egudo", "epuso", "ebuzo", "etsuko", "edzugo")
results_cat$choice <- choices[selected_idx + 1]


# rate同数行を抜き出して横につける。
results_rate <- results_bound %>%
  filter(task == "rate")
rt_rate = results_rate %>% select(rt) %>% unlist %>% as.numeric()
results_rate = results_rate %>% 
  # FIXME: extract_numeric() is deprecated: please use readr::parse_number() instead
  mutate(rate = extract_numeric(response)) %>%
  select(c(rate)) %>%
  unlist()

results_cat$rate <- results_rate
results_cat$rt_rate = rt_rate
results_cat

# 被験者情報とアイテム情報のマージ
results <- results_cat %>%
  left_join(subject_info, by = c("run_id", "data_src")) %>%
  filter(type == "target") %>%
  filter(age > 18) %>%
  select(c(subj_id, tokyo_kinki_ratio, choice, rate, item_id, rt, rt_rate)) %>%
  drop_na() %>%
  merge(item_list, on = "item_id") %>%
  mutate(
    rt = as.numeric(rt),
    stim_devoiced = !str_detect(stim, "u"),
    dev_env = !str_detect(stim, "[dzbg]"),
    pair = case_when(
      stim %in% c("espo", "esupo", "ezbo", "ezubo") ~ "s-p",
      stim %in% c("etsko", "etsuko", "edzgo", "edzugo") ~ "ts-k",
      stim %in% c("epso", "epuso", "ebzo", "ebuzo") ~ "p-s",
      stim %in% c("ekto", "ekuto", "egdo", "egudo") ~ "k-t"
    ),
    supposed_answer = case_when( # 回答が想定通りかを確認
      ("s-p" == pair) & (dev_env) ~ "esupo",
      ("s-p" == pair) & (!dev_env) ~ "ezubo",
      ("ts-k" == pair) & (dev_env) ~ "etsuko",
      ("ts-k" == pair) & (!dev_env) ~ "edzugo",
      ("p-s" == pair) & (dev_env) ~ "epuso",
      ("p-s" == pair) & (!dev_env) ~ "ebuzo",
      ("k-t" == pair) & (dev_env) ~ "ekuto",
      ("k-t" == pair) & (!dev_env) ~ "egudo"
    )
  ) %>%
  distinct()

results
```

選択を縦、音声を横に置いてみる。過度に低いものがないか確認。

```{r}
results %>% ggplot() +
  facet_grid(choice ~ stim) +
  geom_histogram(aes(x = rate), stat = "count")
```

etsko はかなり適切。egudoもよい。egdoは低い。
とくにcat課題で許容度に関しての差はなさそう。

見たいのは環境がdevoicedなのに刺激がvoicedなとき、またその逆の場合に、
東京方言話者が気づくか。

```{r}
results %>%
  filter(choice == supposed_answer) %>%
  ggplot() +
  facet_grid(pair ~ dev_env) +
  geom_boxplot(aes(
    # geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 4),
    y = rate,
    color = stim_devoiced,
    fill = stim_devoiced
  ))
```

統計分析

```{r}
library(lmerTest)
model <- lmer(
  rate ~ stim_devoiced * dev_env * tokyo_kinki_ratio + (1 | subj_id),
  data = results
)
summary(model)
```

> Fixed effects:
                                                Estimate Std. Error         df t value Pr(>|t|)    
(Intercept)                                      4.00708    0.10329   88.89845  38.793   <2e-16 ***
stim_voicedTRUE                                  0.70559    0.05823 3331.00000  12.118   <2e-16 ***
dev_envTRUE                                      0.76758    0.05823 3331.00000  13.182   <2e-16 ***
tokyo_kinki_ratio                               -0.00431    0.13124   88.89845  -0.033    0.974    
stim_voicedTRUE:dev_envTRUE                     -1.11200    0.08235 3331.00000 -13.504   <2e-16 ***
stim_voicedTRUE:tokyo_kinki_ratio               -0.02436    0.07398 3331.00000  -0.329    0.742    
dev_envTRUE:tokyo_kinki_ratio                    0.00383    0.07398 3331.00000   0.052    0.959    
stim_voicedTRUE:dev_envTRUE:tokyo_kinki_ratio   -0.08631    0.10463 3331.00000  -0.825    0.409    

1. 音声が有声だと許容度が上がる
1. 無声化の環境だと(zbでなくspだと)、これもまた許容度が上がる
1. stim_voicedTRUE:dev_envTRUE、つまり無声化の環境(sp)で有声だと下がる
  - これに影響はない。
  - グラフ上はあるんだが...
  - -> 対応付けがあるデータなので、引き算をする

devoiced環境のときに dev-non_dev の値は高くなってほしい。
non-dev 環境のときは 低くなってほしい(non_devのほうが高いので)。

```{r}
# 400件が落ちる
results_match = results %>%
  filter(choice == supposed_answer) %>%
  pivot_wider(id_cols = c(subj_id, tokyo_kinki_ratio, pair, spkr, dev_env),
              names_from = stim_devoiced,
              values_from = rate,
              names_prefix="stim_devoiced_") %>%
  # mutate_all(~replace(., is.na(.), 1)) %>% 
  drop_na() %>% 
  mutate(rate_stim_dev_match = stim_devoiced_TRUE-stim_devoiced_FALSE)

results_match
```

```{r}
results_match %>%
  ggplot() +
  facet_grid(spkr ~ dev_env) +
  # facet_grid(pair ~ dev_env) +
  geom_boxplot(aes(
    # geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 4),
    y = rate_stim_dev_match
  ))
```

```{r}
results_match
library(lmerTest)
model <- lmer(
  rate_stim_dev_match ~ tokyo_kinki_ratio + (1| subj_id)+(1|pair)+(1|spkr),
  # rate_stim_dev_match ~ tokyo_kinki_ratio*pair + (1 | subj_id),
  data = results_match %>% filter(dev_env)
)
summary(model)
```
  
true のときに高くなる。傾向に差はなさそう。
無声化環境で有声はおかしいし、有声化環境で無声化はおかしい。
単に非無声化環境での音声がおかしかった、というものでも解釈できる。

東京方言話者の方は気づいているといって問題なさそう。

```{r}
model <- lmer(
  rate ~ dev_env*stim_devoiced * tokyo_kinki_ratio + (1 | subj_id) ,
  data = results#   %>% filter(dev_env)
)
summary(model)
```

## Appendix

```{r}
# rateを可視化
results %>%
  group_by(stim) %>%
  summarise(rate = mean(rate)) %>%
  print()

# spkr によってひどい差はない
results %>% ggplot() +
  facet_grid(stim ~ spkr) +
  geom_histogram(aes(x = rate), stat = "count")
```

非無声化環境で無声化、あるいは無声化環境で無声化していなければスコアは
低くなっていてほしい。

```{r}
results %>%
  rowwise() %>%
  ggplot() +
  facet_grid(pair ~ stim_devoiced) +
  geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 4),
    y = rate,
    color = dev_env
  ))
```

dev_env がTなのは無声化で、Fは非無声化
青で母音がある（右列）はおかしい。

いや、しかし質が悪かったとして、問題になるのは有声性の効果のみ。

```{r}
print("EOF")
```

---
title: "Categorize and Rate"
output: github_document
---

<!--
最新のドキュメント
https://docs.google.com/document/d/1VywiSaEORlVrRDb7nxGQx2D0pu6huftZrEiVQKmCGWY/edit
論文としてのまとめ方はkilpatrickを参考に進める。
https://drive.google.com/drive/folders/1-Dfuzcas58w9ERrDzoPggfp9vIAjPo7_
昔のもの
https://docs.google.com/document/d/1OKkkZ4sELLtTBjiBWUG_P37EsWdFsidrGv0eOqiwIic/edit?usp=sharing
-->

- 東京方言話者と近畿方言話者で無声化した音声に対する許容度は異なるのか
  - 近畿方言話者にとって無声化の尤度自体は低いはず
    - 無声化しないので P(音声|音素) は低い
    - 聞くことがあるかも知れないので P(音素|音声) も低いとは限らない。
    
> 音がどの表記（ひらがな）に当てはまり(8候補)、
> choices: ['えすぽ', 'えずぼ', 'えくと', 'えぐど', 'えぷそ', 'えぶぞ', 'えつこ', 'えづご'],
> どの程度一致しているかを1--7段階で評価
> questions: [{ prompt: "聞いた音声は選んだ表記として適切ですか？<br>1: 全く適切でない<br>7: 極めて適切", labels: scale }],

- カテゴライズとしての良し悪し
- 3-way interaction
- 交互作用がでたので分析、両方で main effect
  - 有声の方はともかく、無声でも環境と音声のマッチの効果があった
  - -> しかし、区別はできない...
  - 音声としての尤度は判定できるが、どちらも同じラベルを行うので区別はできない。

```{r}
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(tidyr)
source("script/subject_info.R")
source("script/results_pitch.R") # load mutated data
```

1. catのタスクを見る
  1. 想定されたものを選んでもらえたか
  1. 想定されたものとしての評価は低すぎないか
  1. sp とかがナチュラルかも気になる（近畿ではないので）

```{r}
# epuso-1.wavなどのaudio列を.で分割し、最初の要素を stim, spkr とする
item_list <- read_csv("../src/list/cat_list.csv") %>%
  rowwise() %>%
  mutate(
    wav_base = str_split(audio, "\\.")[[1]][1],
    stim = str_split(wav_base, "-")[[1]][1],
    spkr = str_split(wav_base, "-")[[1]][2]
  ) %>%
  select(-c(task, audio, wav_base))

# 被験者情報
subject_info_sone <- read_csv("csv/illusory-vowel-keihan.csv") %>%
  extract_columns(data_src = "sone")
subject_info_cw <- read_csv("csv/illusory-vowel-keihan-cw.csv") %>%
  extract_columns(data_src = "cw")
subject_info <- rbind(subject_info_sone, subject_info_cw) %>%
  mutate(tokyo_kinki_ratio = (span_tokyo - span_kinki) / age)

# cwデータと曽根さんデータのマージ
results_bound <- rbind(
  read_csv("csv/illusory-vowel-keihan.csv") %>% mutate(data_src = "sone"),
  read_csv("csv/illusory-vowel-keihan-cw.csv") %>% mutate(data_src = "cw")
)
```

1. catでの選択を特定
1. rateの抜き出し
1. catのDFの横につける
1. 必要な列を作成
  1. `stim_devoiced`: 刺激はdevoicedされたか
  1. `dev_env`: 無声化環境か
  1. `pair`: どのペアなのか（調音点）
  1. `supposed_answer`: espoもesupoも'えすぽ(esupo)'と回答(choice)してほしい

```{r}
# catでの選択を特定する(indexは1始まりなので+1する)
results_cat <- results_bound %>% filter(task == "cat")
selected_idx <- results_cat %>%
  select(response) %>%
  unlist() %>%
  as.integer()
# choices = c('えすぽ', 'えずぼ', 'えくと', 'えぐど', 'えぷそ', 'えぶぞ', 'えつこ', 'えづご')
choices <- c("esupo", "ezubo", "ekuto", "egudo", "epuso", "ebuzo", "etsuko", "edzugo")
results_cat$choice <- choices[selected_idx + 1]


# rate同数行を抜き出して横につける。
results_rate <- results_bound %>%
  filter(task == "rate")
rt_rate <- results_rate %>%
  select(rt) %>%
  unlist() %>%
  as.numeric()
results_rate <- results_rate %>%
  # FIXME: extract_numeric() is deprecated: please use readr::parse_number() instead
  mutate(rate = extract_numeric(response)) %>%
  select(c(rate)) %>%
  unlist()

results_cat$rate <- results_rate
results_cat$rt_rate <- rt_rate
results_cat

# 被験者情報とアイテム情報のマージ
results_with_outlier <- results_cat %>%
  left_join(subject_info, by = c("run_id", "data_src")) %>%
  filter(type == "target") %>%
  filter(age > 18) %>%
  select(c(subj_id, tokyo_kinki_ratio, span_tokyo, span_kinki, choice, rate, item_id, rt, rt_rate)) %>%
  drop_na() %>%
  merge(item_list, on = "item_id") %>%
  mutate(
    rt = as.numeric(rt),
    stim_devoiced = !str_detect(stim, "u"),
    # FIXME: ちゃんと分けれているか確認
    dev_env = !str_detect(stim, "[dzbg]"),
    pair = case_when(
      stim %in% c("espo", "esupo", "ezbo", "ezubo") ~ "s-p",
      stim %in% c("etsko", "etsuko", "edzgo", "edzugo") ~ "ts-k",
      stim %in% c("epso", "epuso", "ebzo", "ebuzo") ~ "p-s",
      stim %in% c("ekto", "ekuto", "egdo", "egudo") ~ "k-t"
    ),
    supposed_answer = case_when( # 回答が想定通りかを確認
      ("s-p" == pair) & (dev_env) ~ "esupo",
      ("s-p" == pair) & (!dev_env) ~ "ezubo",
      ("ts-k" == pair) & (dev_env) ~ "etsuko",
      ("ts-k" == pair) & (!dev_env) ~ "edzugo",
      ("p-s" == pair) & (dev_env) ~ "epuso",
      ("p-s" == pair) & (!dev_env) ~ "ebuzo",
      ("k-t" == pair) & (dev_env) ~ "ekuto",
      ("k-t" == pair) & (!dev_env) ~ "egudo"
    )
  ) %>%
  distinct()

# 外れ値の対処
hist(results_with_outlier$rt_rate, breaks = 1000)
hist(results_with_outlier$rt, breaks = 1000)
results <- results_with_outlier %>% filter(rt_rate < 10000, rt < 10000)
hist(results$rt_rate, breaks = 1000)
hist(results$rt, breaks = 1000)
# results_with_outlier
```

選択を縦、音声を横に置いてみる。過度に低いものがないか確認。

```{r}
results %>% ggplot() +
  facet_grid(choice ~ stim) +
  geom_histogram(aes(x = rate), stat = "count")
```

<!--
想定どおりの知覚がされた対象のみ行う。
-->
etsko はかなり適切。egudoもよい。egdoは低い。
とくにcat課題で許容度に関しての差はなさそう。

見たいのは環境がdevoicedなのに刺激がvoicedなとき、またその逆の場合に、
東京方言話者が気づくか。

3wayはなさそう。

phonotactics には適しているのに悪くなるのは面白い。
単に devoicedなのに刺激がvoiced の調音、
voicedなのに刺激がdevoicedの調音が悪かっただけ、という線もある。


```{r}
results %>%
  filter(choice == supposed_answer) %>%
  ggplot() +
  # facet_grid(pair ~ dev_env) +
  facet_grid(. ~ dev_env) +
  # geom_boxplot(aes(
  geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 7),
    y = rate,
    color = stim_devoiced,
    fill = stim_devoiced
  ))
```

```{r}
results %>% filter(choice!=supposed_answer)
library(lmerTest)
model <- lmer(
  # 以下はどれでも変わらず
  # rate ~ dev_env * stim_devoiced * span_tokyo + (1 | subj_id),
  # rate ~ dev_env * stim_devoiced * span_kinki + (1 | subj_id),
  rate ~ dev_env * stim_devoiced * tokyo_kinki_ratio + (1 | subj_id),
  data = results %>% filter(choice==supposed_answer)
)
summary(model)
```

正答のみに制限したばあい、大体、平均で4.84くらいの容認度だった。
また、無声化環境（epusoやepso）の場合はそもそも容認度が低かった。
対して、無声化環境かつ無声化しているばあい、容認度は1上がった。
この上がり方に関して、東京と近畿での居住歴の影響はなかった。
なお、東京--近畿だけでなく、純粋な居住歴で分析しても同じ結果だった。

> dev_envTRUE                                     -1.972e-01  5.938e-02  2.885e+03  -3.322 0.000906 ***
> dev_envTRUE:stim_devoicedTRUE                    1.002e+00  8.142e-02  2.885e+03  12.303  < 2e-16 ***
> dev_envTRUE:stim_devoicedTRUE:tokyo_kinki_ratio  6.963e-02  1.031e-01  2.884e+03   0.675 0.499658    

追加の分析として対応づけられたデータの差分を分析する。
つまり、無声化環境のときの無声化、非無声化のレートを被験者ごとに計算する。
例として、「えすぽ」としての評価を[esupo]と[espo]で比較する。
devoiced環境のときに dev-non_dev の値は高くなってほしい。

```{r}
# 400件が落ちる
print(nrow(results))
results_match <- results %>%
  filter(choice == supposed_answer) %>%
  pivot_wider(
    id_cols = c(subj_id, tokyo_kinki_ratio, span_tokyo, span_kinki, pair, spkr, dev_env),
    names_from = stim_devoiced,
    values_from = rate,
    names_prefix = "stim_devoiced_"
  ) %>%
  mutate_all(~replace(., is.na(.), 0)) %>%
  # drop_na() %>%
  mutate(rate_stim_dev_match = stim_devoiced_TRUE - stim_devoiced_FALSE,
         rate_stim_dev_match_odds = log((stim_devoiced_TRUE+1)/(stim_devoiced_FALSE+1)))

print(nrow(results_match))
```

```{r}
results_match %>% filter(dev_env==TRUE) %>% 
  ggplot() +
  # facet_grid(spkr ~ dev_env) +
  # facet_grid(.~pair ) +
  # geom_boxplot(aes(
  geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 4),
    y = rate_stim_dev_match
    # y = rate_stim_dev_match_odds
  ))
```

```{r}
results_match
library(lmerTest)
model <- lmer(
  # rate_stim_dev_match ~ span_tokyo + (1 | subj_id),
  # rate_stim_dev_match ~ span_kinki + (1 | subj_id),
  rate_stim_dev_match ~ tokyo_kinki_ratio + (1 | subj_id),
  data = results_match %>% filter(dev_env=TRUE)
)
summary(model)
```
  
  
データは無声化環境で従属変数は stim_devoiced_TRUE - stim_devoiced_FALSE なので、
仮に無声化の知識が影響するなら。

近畿方言話者がもっている、という解釈はできないか。

(Intercept)       2.117e-01  6.492e-02 1.647e+03   3.261  0.00113 **
(Intercept)       2.117e-01  6.492e-02 1.647e+03   3.261  0.00113 **


(Intercept)       2.117e-01  6.492e-02 1.647e+03   3.261  0.00113 **
  
追加の分析として対応づけられたデータの差分を分析する。
つまり、無声化環境のときの無声化、非無声化のレートを被験者ごとに計算する。
例として、「えすぽ」としての評価を[esupo]と[espo]で比較する。
devoiced環境のときに dev-non_dev の値は高くなってほしい。



特に差はなかった。
true のときに高くなる。傾向に差はなさそう。
無声化環境で有声はおかしいし、有声化環境で無声化はおかしい。
単に非無声化環境での音声がおかしかった、というものでも解釈できる。

## Appendix

```{r}
# rateを可視化
results %>%
  group_by(stim) %>%
  summarise(rate = mean(rate)) %>%
  print()

# spkr によってひどい差はない
results %>% ggplot() +
  facet_grid(stim ~ spkr) +
  geom_histogram(aes(x = rate), stat = "count")
```

非無声化環境で無声化、あるいは無声化環境で無声化していなければスコアは
低くなっていてほしい。

```{r}
results %>%
  rowwise() %>%
  ggplot() +
  facet_grid(pair ~ stim_devoiced) +
  geom_violin(aes(
    x = factor(range01(tokyo_kinki_ratio), 4),
    y = rate,
    color = dev_env
  ))
```

dev_env がTなのは無声化で、Fは非無声化
青で母音がある（右列）はおかしい。

いや、しかし質が悪かったとして、問題になるのは有声性の効果のみ。

```{r}
print("EOF")
```

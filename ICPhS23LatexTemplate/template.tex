\documentclass[a4paper,11pt,twocolumn]{article}

\usepackage{icphs2023}
\usepackage{metalogo} % Only needed for the XeLaTeX logo
\usepackage{epstopdf}
\usepackage{tipa} %
\newcommand{\ipa}{\textipa}
\usepackage{amsmath}% http://ctan.org/pkg/amsmath
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\usepackage{svg}

\hyphenpenalty=10000 % no hyphenation
% 日本語と英語の原稿
% https://docs.google.com/document/d/1df4t0mZm1gUytgQOYaZNg6-mcneA4knqTvUPMIhoMMc/edit?usp=sharing
% https://docs.google.com/document/d/1VywiSaEORlVrRDb7nxGQx2D0pu6huftZrEiVQKmCGWY/edit?usp=sharing

\title{The role of allophones in phoneme perception models: Do devoiced vowels trigger vowel epenthesis?}
% \name{
\author{
    Takeshi Kishiyama$^1$,
    Chuyu Huang$^2$,
    Kei Furukawa$^3$,
    Yuki Hirose$^1$}
% \address{
\organization{
  $^1$Graduate School of Arts and Sciences, The University of Tokyo, Japan\\
  $^2$Faculty of Foreign Studies, Nagoya Gakuin University, Japan\\
  $^3$Nara Institute of Science and Technology, Japan}
\email{
    kishiyama.t@gmail.com,
    huang@ngu.ac.jp,
    furukawa.kei.fi4@is.naist.jp,
    hirose@boz.c.u-tokyo.ac.jp
    }
\begin{document}

\maketitle

\begin{abstract}
This study investigated how phoneme perception models should incorporate allophones, leveraging dialectical differences among Japanese. It has been reported that listeners of a language that disallows consonant clusters insert epenthetic vowels, or illusory vowels, to repair illegal consonant clusters, thus, for example, perceiving VCCV as VCVCV. In addition to the roles of phonotactic constraints and acoustic cues, recent studies have indicated that allophones such as devoiced vowels in the Tokyo dialect also facilitate perceptual epenthesis. We obtained the discrimination accuracies of VCCV and VCVCV perception in Kansai dialect speakers, who are reported to have less devoiced vowels. Both Tokyo and Kansai speakers perceived illusory vowels, indicating that illusory vowels were perceived even by speakers without devoicing. Furthermore, the results suggest that discriminative models other than probabilistic models assuming an auditory realization distribution can be psychologically valid.
\end{abstract}

\keywords{speech perception, phonotactics, context effects, perceptual epenthesis, dialect}

\section{Introduction}

% TODO: Grammarlyにもう一度かける(GitHub上でできるはず)
Hearing speech sounds violating the phonotactics of the native language, the listener perceives the phonemes according to the rules. For example, native Japanese speakers perceive [ebzo] as /ebuzo/ according to their phonotactics. The \textit{illusory vowel} is perceptually inserted for stimuli where the vocal fold vibration of the vowel is acoustically absent \cite{dupoux1999epentheticvi, dupoux2011illusory}. Recently, devoicing and allophones have been reported to affects the illusion, and our study reexamined these effects through experiments on dialect speakers and discussed how we should incorporate them into perceptual models.

First, phonotactics provide insights into the vowel illusion \cite{dupoux1999epentheticvi, halle2014special, monahan2009not, mattingley2015influence, guevara2017predicting, guevara2017epenthetic}, as shown in an experiment with native French and Japanese speakers \cite{dupoux1999epentheticvi}. Unlike French, Japanese disallows the consonant cluster /bz/, and the speakers of each language tried to discriminate between [ebuzo] and [ebzo] in the experiment. While French speakers successfully distinguished them, Japanese speakers perceived [ebzo] as /ebuzo/, which decreased their discrimination accuracy.

In addition to the phonotactics, experiments with native speakers of Brazilian Portuguese and Japanese have revealed the influence of acoustic cues on illusory vowels \cite{dupoux2011illusory}. Both languages do not allow /bz/, and the default vowels to be inserted are /i/ and /u/, respectively. The study deleted the vowels between /b/--/z/ in [ebizo] and [ebuzo], leaving the vowels' acoustic cues in /b/. The remained cues affected the subjects of both languages, increasing the insertion rate of the non-default /i/ for Japanese.

Based on these results, previous research has assumed one-step models, where phonotactics and acoustic cues affect the illusion simultaneously. The one-step models can be represented by hidden Markov models (HMMs), which can also represent perceptual assimilation models \cite{best2001discrimination} and models in exemplar theory \cite{lacerda1995perceptual}, having reproduced the illusory vowels \cite{kishiyama2021influence} by calculating Equation 1. The equation calculates two likelihoods: $P(c|c_{t-1})$ represents the likelihood of the phoneme array $c_{t-1}$ to $c$, and $P(S_{\text{new}}|c)$ represents the likelihood of the input speech $S_{\text{new}}$ for a phoneme $c$. Consequently, the phoneme $c$ that maximizes the likelihoods is activated as $\hat{c}$.
% no break
\begin{equation} \label{hmm}
    \hat{c} = \argmax_{c} P(c | c_{t-1})P(S_{\text{new}}|c)
\end{equation}
% no break
% In the models above, acoustic cues such as coarticulation effects which phoneme would be activated. For example, the stimulus $S_{\text{new}}$ that contains the auditory feature of /i/ would make $P(S_{\text{new}}|\text{/i/})$ higher than $P(S_{\text{new}}|\text{/u/})$, changing the final $\hat{c}$. By contrast, allophones that belong to a single phoneme do not affect which phoneme to be activated because they are perceived as the same phoneme. 
% ↑ の部分は下のパラグラフ(The question is ... )で説明するから省ける。
Traditionally, the unit assumed as $c$ above was phonemes \cite{wilson2013bayesian}. Recent studies, however, have suggested that allophones should be treated as discrete units in perceptual models.

First, devoiced/deleted vowels in Japanese are reported to increase the perceptual epenthesis \cite{kilpatrick2018japanese}. Tokyo-dialect in Japanese deletes the high vowel /u/ in /esupo/, and it would be [espo] when the vowel follows fricatives or affricates \cite{fujimoto2003devoice_eng, shaw2018lingual}. In other cases, the vowel in /epuso/ becomes devoiced as [ep\textsubring{\textturnm}so]. The study reported that the deletion/devocing encouraged assimilation and increased the perceptual epenthesis. Furthermore, transition probabilities between allophones are reported to cause vowel illusion \cite{kilpatrick2020japanese}. Japanese [\textctc], a realization of /s/, precedes /i/ but not other vowels. The study investigated whether [\textctc{}] induces the illusion of /i/ more \cite{kilpatrick2020japanese}, and found that the /i/ was perceived more frequently after [\textctc] than after [g]. These result suggests that allophones and their transition probabilities affects the vowel illusion.

The question is whether phoneme perception models should consider the allophones categorical rather than continuous. Without assumption of categorical allophones, models including the one-step models can explain the results above. The difference in the auditory cues within the deleted and devoiced vowels yield different $P(S_{\text{new}}|c)$ in Eq. (1). Furthermore, the stimuli [\textctc] is supposed to have acoustic cues of /i/ \cite{kubozono1999japanese_eng}, which can also change $P(S_{\text{new}}|c)$ in Eq. (1). To explain the results, therefore, the models do not need to have categorical allophones.

What allows multiple interpretations for the experiments is the confounding of the allophones and the acoustic cues, and we leveraged dialectal differences between the Kansai and Tokyo dialects in Japanese \cite{kishiyama2022onestep}. First, in [ep\textsubring{\textturnm}so] and [espo], not only the allophones (devoiced/deleted) but also the immediately preceding speech sounds ([p]/[s]) are different. In addition, in comparisons of [egpo] and [e\textctc{}po], the transition probability from [g] or [\textctc] to the next vowel is confounded with the acoustic cues of [g] or [\textctc]. We can deal with this issue using the Kansai dialect speakers, who tend to devoice/delete vowels less frequently than the Tokyo dialect speakers do \cite{byun2011_eng, byun2012_eng}. According to the assumption that the deletion and devoicing caused the illusion, the Kansai-dialect speakers, who are less exposed to those allophones, should yield few illusion and more accurate responses in discriminative AXB tasks.

\section{Perception experiment}

% The perceptual task examines how devoicing and deletion increase the illusion. If deletion or devoicing vowels increase the perceptual illusion, the discrimination accuracy in the AXB task would be lower for Tokyo dialect speakers, who have more frequent contact with the variation. The opposite pattern is expected among the Kinki dialect speakers, who have less frequent or don't have contact with those.

\subsection{Materials and methods}

%FIXME: MやSDの値をダブルチェク
We used an outsourcing service to recruit subjects who were older than 18 years and from Tokyo or the Kansai region, and those who had never lived in other areas since birth had priority in the recruitment process. We had 62 valid subjects participated in the experiment ($M$=40, $SD$=15), while excluding the results of the four subjects whose answers were under 75\% accuracy in the categorization task (\S3).

In the AXB task, the participants were to distinguish between VC$_\text{1}$VC$_\text{2}$V and VC$_\text{1}$C$_\text{2}$V in a list of target stimuli with 32 items based on the combination of the four conditions below. (1) For environments where deletion and devoicing occur, we established four pairs for C$_\text{1}$C$_\text{2}$: s--p, k--t, p--s, and ts--k. (2) We also had stimuli VC$_\text{1}$VC$_\text{2}$V with /u/ between C$_\text{1}$ and C$_\text{2}$ that the participants had to discriminate from VC$_\text{1}$C$_\text{2}$V. (3) We also created two patterns depending on whether a trial's stimulus in the X position was either VC$_\text{1}$VC$_\text{2}$V or VC$_\text{1}$C$_\text{2}$V, which is to be distinguished in the AXB task. (4) We prepared voiced counterparts of C$_\text{1}$ and C$_\text{2}$, such as b--z, where neither deletion nor devoicing occurs. The positions of correct answers were counterbalanced, A or B.

We recorded stimuli from three male speakers and adjusted the loudness to 75 dB. The duration before C$_\text{2}$ was about 50 ms (about 400 ms for the entire three moras) so that the subjects would not perceive a long blank as the "geminate" consonant, a distinctive phoneme \textit{sokuon} in Japanese. We removed the voicing parts of /egudo/ and /ebuzo/ based on formant and power and extended the silent interval. In this case, the cycle of each preceding waveform was duplicated and extended. In contrast, /u/ in /epuso/ was cut so that it would be of the same duration as /epuso/.

After three sets of practice tasks, 32 target items and 24 filler items were randomized and presented to the subjects in an experimental environment conducted on web browsers. A "+" was displayed in the center of the screen for 1000 ms before the audio stimuli, and the three audio items were presented at intervals of 200 ms. After the presentation was over, the subject was to respond as quickly as possible. We didn't feed back correct or incorrect to avoid learning during the task, and the program only provided answers in the practice task. When a trial ended, the participants could start the next trial by pressing the space key.

\subsection{Results}

The y-axis in the Figure \ref{fig:axb_results} shows the average discrimination accuracy of VC$_\text{1}$VC$_\text{2}$V and VC$_\text{1}$C$_\text{2}$V in the AXB discrimination task. On the left and right panes, we indicated whether the stimulus was in devoicing environment (e.g., k--t if C$_\text{1}$C$_\text{2}$ was devoicing condition, g--d if not). The x-axis shows the Tokyo--Kansai ratio, the ratio of residential history between Tokyo and the Kansai region. For example, if a subject has lived in Tokyo for 25 years and in Kansai for 15 years, the ratio is $(25-15)/40$, or $0.25$. We showed four items vertically to see tendencies for each item,

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=7cm]{../results/artifact/results_axb_allophone.pdf}
\caption{A boxplot that shows the relationship between the residential history and perceptual illusion.}\label{fig:axb_results}
\end{center}
\end{figure}

% FIXME: この1%は Place holder
We checked the distribution of the reaction time data and excluded the 1\% of data with a reaction time of 10 seconds or longer as outliers. We calculated the mean accuracy, averaging four patterns based on the X in AXB (VC$_\text{1}$VC$_\text{2}$V or VC$_\text{1}$C$_\text{2}$V) and the correct answer position (A or B) and excluding missing values.

% FIXME: Table を追加するか検討
We created a Bayesian linear mixed-effects model \cite{lme4, rstanarm, easystats} with the Tokyo--Kansai ratio as the independent variable and the AXB task discrimination accuracy as the dependent variable. Item type and subjects were modeled as random effects. The analysis revealed an overall mean accuracy of 0.59, without consistent effects for environmental. The estimates of dialectal differences were positive (0.019) and not in the direction of decreasing precision.

% FIXME: Bayes Factor 周りの記述を再読して修正
% https://easystats.github.io/bayestestR/articles/bayes_factors.html
Although we found no effect of the residence ratio, a Bayes factor ($BF$) for the Tokyo--Kansai ratio was calculated to evaluate the null-hypothesis. The Bayes factor was 0.150, providing substantial evidence for the null-hypothesis. In the framework of Bayesian statistics, the Bayes factor is used as a decision-making index when comparing and discussing the effects of models and factors. Bayes factor can be derived in several ways, but in this study, we used as following.

$$
BF = \frac{Posterior \text{ }Odds }{Prior \text{ }Odds}
$$

Each $Odds$ above calculates the ratio of (i) the probability of the factor's effect to (ii) the probability supporting the \textit{null-effect}\cite{kruschke2010believe}. This time, the factor was the Tokyo--Kansai ratio, an independent variable whose effect was supposed to be negative. Therefore, the null-region, considered to have no effect, was set to a positive value [0, $\infty$]. The probability of effect is the probability that slope $b$ falls outside the null-region. In contrast, the probability of no effect is the probability that it falls within the region. The $Prior \text{ }Odds$ is calculated based on the prior distribution, whereas $Posterior \text{ }Odds$ is calculated based on the observed data.

$$ Prior\text{ }Odds = \frac{P(b\notin[0, \infty])}{P(b\in[0, \infty])} $$

$$ Posterior \text{ }Odds = \frac{P(b\notin[0, \infty] | Data)}{P(b\in[0, \infty] | Data)} $$

The $BF$ of the Tokyo--Kansai ratio was 0.15 when the null-region was set to [0, $\infty$] in this analysis, which indicated that the null-hypothesis of a positive effect was $1/0.15(=6.67)$ times more plausible than the alternative hypothesis of a negative effect. This result contradicts the interpretation that the allophone increases the rate of illusions and reduces the accuracy.

\subsection{Discussion}

If the allophone creates the illusion of a vowel, the Tokyo dialect speakers with the allophone should have lower accuracy in the discrimination experiment than speakers without devoicing. However, the results of the AXB task showed that the discrimination accuracy of both Kansai and Tokyo dialect speakers, regardless of their language experience, was around 0.59, which is close to a chance level. In addition, the $BF$ suggested that the language experience and devoicing did not affect the rate of illusions in the discrimination task.

% Next, we conducted an offline categorization task to confirm that Kansai dialect speakers perceive the stimuli the same way as Tokyo dialect speakers. This experiment provides information on the acceptabilities of the stimuli and the subject's rate of correct responses to the task. It also provides an offline evaluation of the illusion.

Next, categorization task investigated dialectal differences and acceptability judgments about devoicing in offline processing. We examined whether dialect differences in language experience affect the goodness rating of deletion/devoicing. Note that we performed this categorization task after the online process to avoid any effect on the validation of the online process.

\section{Categorization task}

\subsection{Materials and methods}

The same subjects participated in the perceptual task. All speech sounds presented in the perceptual experiment were to be classified. There are a total of eight different patterns: four environments to be devoiced in the Tokyo dialect (esupo, ekuto, epuso, etsuko) and four devoiced settings (espo, ekto, epso, etsko). The choices were shown in Japanese letters on the screen, and the correct ones were esupo, ekuto, epuso, and etsuko, respectively. In the environment where devoicing does not occur, each of the above eight patterns of consonants is switched to voiced sounds, and the correct responses were ezubo, egudo, ebuzo, and edzugo, respectively. Since three speakers recorded 16 patterns, the subjects listened to 48 stimuli.

Subjects listened to the stimuli, selected which of the above eight options shown above was closest to it, and immediately rated its acceptability on a 7-point scale (0--6). In the goodness of fit rating, zero was considered "not appropriate at all," and six was considered "completely appropriate."

\subsection{Results}

% FIXME: 色を修正
The x-axis in the Figure \ref{fig:cat_results} shows the Tokyo--Kansai ratio and the y-axis shows the goodness of fit rating. The left and right panes indicate the environment of speech (devoicing or not), and the color difference is shown in blue when the actual stimulus was devoiced and in red when it is not.

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=7cm]{../results/artifact/results_categorization.pdf}
\caption{A boxplot that shows the relationship between the residential history and the goodness of fit rating.}\label{fig:cat_results}
\end{center}
\end{figure}

The figure shows The overall ratings were above the mean of 3. In the left pane, which represents the devoiced environment, the ratings of the devoiced stimulus were higher, as shown in blue. In contrast, the right pane, which represents the no-devoicing environment, suggests the devoiced stimulus decreased the ratings. The residential history does not contribute to these differences.

% FIXME: table追加は検討(直近では含まない方向)
To test these points, we created a Bayesian linear mixed-effects model with the goodness of fit rating as the dependent variable. Five independent variables were environment (devoicing/no-devoicing), stimulus type (devoiced / not devoiced), the Tokyo--Kansai ratio, an interaction between the three variables, an interaction between environment and stimulus, and an interaction of the three factors. Subjects and items were random effects. As a prior distribution for each parameter, we employed a normal distribution with a mean of 0 and a standard deviation of 10, which we consider a uniform distribution with a sufficiently wide range.

% Table X below shows the coefficients, sd, and 95\% Bayesian confidence intervals for each factor obtained by MCMC sampling. All Rhat values were one, and the model converged.

% Below is the table which summarizes statistics whose 95\% Bayesian confidence interval did not include 0.
As a results, the mean rating was 4.87, indicating that the evaluation was generally natural, given that the rating range was 0--6. The devoicing environment and the devoiced stimulus were $-0.37$ and $-0.79$, respectively. Furthermore, the interaction, i.e., the devoiced stimulus in the devoiced environment, increased the rating by 1.19. The $BF$ for the Tokyo--Kansai ratio was 0.012 when the null region was set to $[-\infty, 0]$, indicating robust evidence of no effect.

\subsection{Discussion}

The results showed that the overall responses were above 4, which means that the quality of the stimuli in this study was not lower than in previous studies \cite{kilpatrick2018japanese}. If the subjects can judge the devoiced speech in the Tokyo dialect offline without epenthesis, then the goodness rate of devoiced stimuli would be above three because it is appropriate in devoicing environment and less than three if it is in a no-devoicing environment. In contrast, when vowels are inserted, all are appropriate and acceptable; thus, responses would be above 4.

The results of the categorization task showed that both Tokyo dialect and Kansai dialect speakers showed higher ratings when the environment and speech were in the Tokyo dialect. In other words, the results showed that the rating increased when the speech was devoiced in a devoicing environment. At the same time, it decreased when the devoiced stimuli were in the no-devoicing environment. However, the effect was only about 1, not high enough to cross the threshold between unnatural and natural.

\section{General Discussion}

Previous research proposed that the vowel illusion was caused by devoicing. In addition, probabilistic models included the distribution of auditory realizations. This study proposes a different interpretation based on the results of perceptual experiments and categorization tasks.

First, the results of the discrimination accuracy and categorization tasks in the previous studies were not due to the effect of devoicing but to acoustic differences. Suppose the perceptual epenthesis was due to the devoicing or deletion. In that case, the discrimination accuracy of Tokyo dialect speakers should be lower than that of Kansai dialect speakers who do not devoice or delete the vowels, but there was no such effect. Instead, the Kansai dialect speakers perceived the illusory vowels as the Tokyo dialect speakers do in our study.

Second, regarding how acoustic cues affect speech perception, previous studies \cite{wilson2013bayesian, kishiyama2021influence} have assumed Eq. \ref{hmm} during inference. On the right-hand side, $P(S_{\text{new}}|c)$ is thought to represent the distribution of auditory realizations for phonemes or the perceptual likelihood of $S_{\text{new}}$ given $c$. This formula makes the results consistent with the previous study because $P$( [\textsubring{\textturnm}] | /u/ ) or $P$( [s] | /su/ ) is not zero given that the Kinki dialect speakers hear them since these are in Tokyo-dialect, which are prevalent in Japan. Given Bayes Theorem, however, the equation can be rewritten as Eq. (\ref{disc}).

% cˆ = argmax c P(c|ct−1) (P(c |Snew )/P(c))
% FIXME: ここの修正
\begin{equation} \label{disc}
    \hat{c} = \argmax_{c} P(c | c_{t-1}) \frac{P(c|S_{\text{new}})}{P(c)}
\end{equation}

The equation above implies that the above equation integrates a discriminative model rather than a generative model with the auditory distribution. Thus, it can employ other discriminative models, such as neural networks and multinomial logistic regressions. Since previous studies have already supported the validity of HMMs \cite{kishiyama2021influence}, we will test whether we can incorporate the above discriminative model into HMMs to explain behavioral data.

\bibliographystyle{IEEEtran}

\bibliography{mybib}

\end{document}
